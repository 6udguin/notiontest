# 파이썬 딥러닝 텐서플로

- PART01 개발 환경 구축
    
    
    - 01 구글 코랩
        
        ```java
        탠서플로는 딥러닝을 위한 도구이고, 수많은 행렬 곱셈 연산을 처리한다. 따라서 병렬 연산이 가능한 GPU 환경에서 동작하는 것이 좋다. CPU 환경에서도 텐서플로 사용이 가능하지만, 딥러닝 모델의 학습 속도를 고려했을 때 GPU가 필수적이라고 볼 수 있다.
        
        텐서플로 개발 환경을 구축할 때 성능이 좋은 그래픽 카드(GPU)가 필요하다. 일반적으로 엔디비아 RTX급 이상의 GPU를 많이 사용하는데, 연산을 담당하는 CUDA 코어 개수가 많고 그래픽 카드 메모리(VRAM)가 클수록 딥러닝 개발 환경에 적합하다. 데이터를 저장하는 메모리와 연산을 처리하는 텐서 코어를 연결하는 메모리 대역폭(bandwidth)도 중요한 요소다.
        
        최근 비트코인 등 암호화폐 가격 상승으로 채굴 수요가 급증하고 있다. 성능 좋은 GPU가 품귀 현상을 빚으며 가격이 계속 올라가고 있다. 따라서 이 책을 구성할 때 무료 클라우드 환경에서 제공하는 GPU로 학습이 가능하도록 실습 예제를 구성했다. 즉, GPU가 탑재된 컴퓨터가 없어도 기본적인 텐서플로 학습이 가능하다는 점을 강조하고 싶다.
        ```
        
        ```java
        구글 코랩(Google Colab)은 텐서플로를 가장 쉽게 사용할 수 있는 방법이라고 말할 수 있다. GPU(그래픽 카드)를 따로 구입할 필요도 없다. 구글 클라우드 환경에서 지원하는 GPU를 무료로 이용할 수 있기 때문이다. 또한, 텐서플로를 설치할 필요도 없기 때문에 딥러닝을 처음 배우거나 고성능 GPU가 없는 독자들에게 권장하는 분석 도구이다.
        ```
        
    - 02 구글 코랩 설치
        
        ```java
        1. 웹 브라우저를 열고 구글 계정에 로그인한다. 검색창에 'google colab'을 입력하고 검색한다.
        
        2. 검색 결과에서 Google Colab 링크를 찾아서 선택한다.
        
        3. 다음과 같이 코랩 메인 화면이 나타난다. 오른쪽 하단의 [새 노트]를 선택하면 새 노트북 파일이 실행된다. 이 노트북에 파이썬 코드를 입력할 수 있다.
        ```
        
    
    - 03 구글 코랩 실행
        
        ```java
        1. [새 노트]를 열면 다음과 같은 화면이 나온다. 왼쪽 위에 'Untitled0.ipynb'라는 파일명이 보인다. 파일명을 클릭해서 수정할 수 있다.
        
        2. 코랩은 기본적으로 CPU 환경을 지원한다. GPU를 선택하려면 화면 상단의 [런타임] 메뉴에서 [런타임 유형 변경]을 클릭한다.
        
        3. 하드웨어 가속기 중에서 기본값으로 설정된 None은 CPU를 뜻한다. GPU를 사용하려면 GPU를 선택하고 [저장]을 누른다.
        
        4. 밝은 회색 바탕의 네모난 영역을 '코드 셀'이라고 부른다. 코드 셀에 다음과 같이 텐서플로 라이브러리를 불러오는 import tensorflow as tf 코드를 입력한다. Enter를 누르면, 다음 줄에 코드를 입력할 수 있다. 여기에 텐서플로 버전을 화면에 출력하는 print 명령을 입력한다. 코드 셀에 입력한 코드를 실행하려면 왼쪽의 재생 표시 버튼을 클릭하거나, Shift + Enter를 동시에 누른다. 코드 셀의 아래 부분에 실행 결과가 표시된다. 이 책을 쓰는 시점에 구글 코랩은 텐서플로 2.4 버전을 지원하는 것을 알 수 있다.
        ```
        
    - 04 예제 코드 복사하기
        
        ```java
        코랩 사용 시 깃허브(github)에서 예제 코드를 받는 방법은 두 가지가 있다.
        * 첫 번째 : 깃허브에서 다운로드 받은 후, 구글 드라이브에 업로드하는 방법
        * 두 번째 : 구글 코랩 실행 후, 구글 드라이브로 바로 복사하는 방법
        
        이 책에서는 두 번째 방법으로 설명한다(본 예제 외에도 다른 깃허브에 있는 노트북이나 데이터를 구글 드라이브로 복사해 올 때 유용하게 활용할 수 있다).
        
        1. 구글 코랩 실행 후 [연결]을 통해 "RAM"과 "디스크"가 표시됨을 확인한다.
        
        2. 왼쪽 메뉴바 4번째 "폴더" 모양을 선택한 후 구글 드라이브 폴더를 클릭한다.
        
        3. Google Drive 액세스 권한이 필요하다. [GOOGLE DRIVE에 연결] 버튼을 클릭한다.
        	연결이 되었다면 [drive]폴더와 [구글 드라이브 마운트 해제] 아이콘이 나타난다.
        
        4. 예제 파일을 복사할 위치를 구글 내 드라이브에서 찾는다. 새 폴더를 생성해도 된다. 폴더를 정했다면 [...]을 클릭한다. 
        
        5. 경로를 복사한다. 경로를 정확히 알고 있다면 이 부분은 생략해도 된다.
        
        6. 새 폴더를 만들었는데 나타나지 않는다면 [새로고침] 아이콘을 클릭한다.
        
        7. 코드를 통해 깃허브에 있는 예제 파일을 복사해온다. 아이콘으로 구글 드라이브가 연결되지 않으면 다음과 같은 코드를 사용하여 연결하는 방법도 있다(단, 출력에 나타나는 링크를 통해 구글 계정 연결 및 코드 복사 및 붙여넣기가 필요하다).
        
        앞에서 구글 드라이브에 잘 연결되었다면 다음 첫 번째 코드셀의 내용은 생략해도 된다.
        
        ```
        
        <소스>1.1_hithub_code.ipynb
        
        ```python
        #[1] 구글 드라이브 연결
        from google.colab import drive
        drive.mount('/content/drive')
        
        #[2] 리눅스 "pwd" 명령어를 통해 현재 경로를 확인한다.
        pwd
        
        #[3] cd "/content/drive/MyDrive/Colab Notebooks"
        
        #[4] 파일이 복사할 폴더로 잘 이동되었는지 "pwd" 명령어를 통해 다시 확인한다.
        pwd
        
        #[5] 깃허브에 있는 예제 파일을 내 구글 드라이브로 복사한다.
        !git clone https://github.com/lovedlim/tensorflow.git
        ```
        
        1. 크롬 웹브라우저를 통해 구글 드라이브에 복사된 파일을 확인한다. 
        2. 파트별 예제 파일을 실행해보자. 일반적으로 구글 드라이브에서 노트북 파일을 더블클릭하면 코랩으로 실행되지만, 때에 따라서(설치된 앱이 많을 경우)는 마우스 오른쪽 버튼을 클릭해 연결 앱을 지정해야 할 수도 있다. 이때, 코랩이 설치되어 있지 않았다면 [연결할 앱 더보기]에서 “colaboratory”를 검색해 설치한다.

- PART02 텐서플로(TensorFlow)
    - 01 텐서플로
        
        텐서플로(TensorFlow)는 2015년 구글 브레인 팀에 의해 공개된 대표적인 머신러닝 라이브러리이다. 파이썬뿐만 아니라, 자바스크립트나 Swift를 사용하여 모델을 개발하고 배포할 수 있는 다양한 도구를 지원하고 있다. 이처럼 텐서플로는 머신러닝과 딥러닝 기술을 개발하는 데 멈추지 않고, 텐서플로로 개발한 인공지능 기술이 적용된 서비스를 웹 또는 모바일을 통해 배포하는 데도 활발하게 사용된다.
        
        텐서플로는 딥러닝 연산을 처리하는 라이브러리이다. 텐서플로라는 이름에서 알 수 있듯이 텐서(Tensor)라고 부르는 데이터를 계산 그래프(Computational Graph) 구조를 통해 흘러가면서(Flow) 복잡한 행렬 연산을 처리하게 된다.
        
        먼저 노드(node)와 노드 사이를 연결하는 간선(edge)으로 이루어진 그래프 구조를 만들고, 노드 사이에 연결된 간선을 통해 데이터를 이동시킨다. 이때 데이터에 대한 연산은 각 노드에서 이루어진다.
        
        [그림 2-2}는 텐서플로 계산 그래프를 그림으로 표시한 것이다. 그래프의 각 노드에서는 add, matmul 등 정해진 연산을 처리한다. 노드 사이의 간선 화살표 방향을 따라 텐서 형태의 데이터가 이동한다. 다시 말하면, 한 노드에서 연산을 처리한 뒤 화살표 방향으로 연결된 다음 노드로 텐서가 이동하고, 도착한 노드에 정의된 연산을 처리한다. 이처럼 텐서라는 데이터가 노드에서 노드로 간선을 따라 흐르면서 복잡한 연산을 순서대로 처리하게 된다.
        
        ```python
        	Y = sigmoid(ax+b)
        
        a                      x                       b
        ->   [matmul]         <-                       |
               |                                       |
        		   ->               [add]                 <-
                                  |
        													|
        								    		[sigmoid]
                                  |
        											    |
        												 output
        ```
        
        <aside>
        🚓 [Tip] 이 책에서는 텐서플로 사용법과 텐서플로를 이용한 딥러닝 기법을 중심으로 설명한다. 계산 그래프에 대한 구체적인 설명은 이 책의 범위를 넘어서기 때문에 추가 설명을 생략한다.
        
        </aside>
        
        텐서플로는 딥러닝에 필요한 고차원의 복잡한 연산을 빠르고 효율적으로 처리할 수 있기 때문에 전세계 많은 개발자들과 기업들이 활용하고 있다. 또한, 배우기 쉽고 사용하기 편리한 파이썬 언어를 사용하는 장점이 있어 거대한 사용자 커뮤니티를 형성하고 있다. 최근 급성장하고 있는 파이토치(PyTorch)와 함께 딥러닝 분야에서 가장 많이 활용되고 있다.
        
        현재 공식 버전인 텐서플로2에서는 고수준(high-level) API인 케라스(Keras)를 통합하여 머신러닝 및 딥러닝 모델을 쉽게 구축하고 즉시 실행해 볼 수 있다. 이처럼 사용자 편의성을 확대하기 위한 노력이 이어지는 등 구글의 강력한 지원을 받고 있기 때문에 텐서플로의 영향력은 계속 이어질 것으로 보인다. 특히, 개발사인 구글 내에서도 AI 기술이 적용된 음성 인식 등 다양한 서비스를 구현하는 데 활발하게 사용되고 있기 때문에 높은 점유율을 유지할 것으로 예상된다.
        
    - 02 텐서플로2 주요 특징
        
        
        2019년에 출시된 텐서플로2를 이전 세대인 텐서플로1과 구별 짓는 가장 큰 차이점은 즉시 실행(eager excution)모드를 지원하는 것이다.
        
        - 2-1 즉시 실행
            
            
            텐서플로1은 딥러닝 연산을 처리할 그래프 구조와 세션(session)을 먼저 만들고, 여기에 데이터(텐서)를 입력하고 연산하는 과정을 나중에 별도로 실행하기 때문에 2단계로 구성하는 개념이었다. 중간 계산 결과를 확인하려면 그래프를 생성하기 위해 반드시 세션을 실행해야한다는 점 때문에 번거롭고 디버깅을 어렵게 한다는 단점이 있었다. 또한 코드 구성 방법이 일반적인 파이썬 문법과 차이가 있어서 처음 사용법을 익히는 데 어려움이 큰 편이었다.
            
            하지만 텐서플로2는 즉시 실행을 기본 모드로 사용한다. 별도로 세션을 정의하지 않아도 파이썬 함수로 모델 학습이 가능하다. 즉시 실행이 가능해지면서 여러 가지 장점이 생겼다.
            
            1. 첫째, 모델 구조를 만들고 학습을 진행하는 과정이 직관적이다.
            2. 둘째, 실행 결과를 바로 확인할 수 있기 때문에 오류를 수정할 수 있는 디버깅 과정이 편리하다.
            3. 셋째, 그래프 구조를 생각하지 않아도 되고, 파이썬 프로그래밍의 제어 도구를 활용해서 모델 학습 과정을 설계할 수 있다.
            
            예제를 통해 즉시 실행 모드를 확인해 보자. 다음과 같이 텐서플로 라이브러리를 불러와서, executing_eagerly() 함수를 실행하면 즉시 실행모드인지 여부를 확인할 수 있다. 출력 값이 True로 나오면 즉시 실행 모드가 설정된 상태이다. False이면 텐서플로1과 같은 그래프 실행 모드라는 뜻이다.
            
            >> print(tf.executing_eagerly())
            
            실제 계산 결과를 바로 확인할 수 있는지 확인해 본다. 다음 코드에서 변수 a, b에 정수 1과 2를 각각 대입한다. 텐서플로 math 모듈의 add 함수를 사용해 두 변수의 값을 더하고 변수 c에 저장한다.
            
            print 함수로 변수 c에 할당도니 값을 출력하면 텐서에 숫자 3이 정수형(int32)으로 저장되어 있는 것을 알 수 있다. 이처럼 별도의 컴파일 과정을 거치지 않고 파이썬 일반 연산과 같이 노트북 환경에서 바로 실행되고 결과를 확인할 수 있다.
            
            ```python
            a = 1
            b = 2
            c = tf.math.add(a, b)
            print( c )
            
            # tf.Tensor(3, shape=(), dtype=int32)
            
            ```
            
            변수 c에 저장되어 있는 텐서 객체로부터 덧셈의 결과값인 3을 추출하려면, 텐서를 나타내는 변수 이름 뒤에 numpy() 메소드를 입력한다. 이처럼 중간 계산 결과를 바로 확인할 수 있다.
            
            ```python
            c.numpy()
            
            # 3
            ```
            
        
        - 2-2 고수준 API 지원
            
            
            이전 세대인 텐서플로1과 달리, 텐서플로2에서는 고수준(high-level) API인 케라스를 텐서플로 라이브러리 안에 통합하여 제공한다. 따라서 별도로 케라스 라이브러리를 설치할 필요가 없다. 또한, 케라스를 잘 다루면 대부분의 텐서플로 기능을 활용할 수 있다.
            
            케라스는 입문자 또는 비전공자도 쉽게 사용법을 익힐 수 있다는 장점이 있다. 케라스 기본사용법을 익히면 다양한 딥러닝 프로젝트를 직접 만들 수 있다.
            
            한편 특별한 기능을 구현하거나 모델 학습을 직접 컨트롤하기를 원하는 고급 사용자의 경우, 텐서플로 고유의 저수준(low-level) API를 사용하면 된다. 이처럼 텐서플로는 다양한 사용자 요구 수준에 대응할 수 있다는 장점이 있다.
            
            텐서플로는 파이썬 뿐만 아니라, C++, JAVA 등 다른 언어도 지우너하고 있다. 그 중에서도 파이썬은 텐서플로 고유의 저수준 API ( Layers, Datasets )를 활용할 수도 있고. 그 보다 상위에 있는 케라스 모델을 사용할 수도 있다. 케라스는 텐서플로 저수준 API인 Layers와 Datasets와 같은 백엔드 자원을 활용하여 그 기반 위에서 만들어지는 개념이다.
            
            ```python
            [Pre-made Estimators]
            [Estimator] [Keras Model]
            [Layers]    [Datasets]
            [Python Frontend]   [C++] [Java] [Go] [...]
            [TensorFlow Distributed Execution Engine]
            [CPU] [GPU] [TPU] [Android] [XLA]
            [IOS][...]
            
            <텐서플로 아키텍쳐>
            ```
            
        - 2-3 자동 미분
            
            
            텐서플로는 딥러닝 모델 학습에 필요한 복잡한 미분(differentiation)을 자동으로 계산해 준다. 딥러닝 모델은 인간의 뇌 신경 구조를 모방한 인공 신경망으로 구현되는데, 인간의 뇌만큼 복잡한 구조를 갖는다. 복잡한 인공 신경망의 구조를 복잡한 수학적 함수식으로 표현하게 된다. 이때 딥러닝 모델이 예측과 실제값과의 오차를 최소로 하는 함수식을 찾기 위해 복잡한 함수를 미분하는 과정이 필요하다. 이때 텐서플로는 미분을 자동으로 계산해준다.
            
            딥러닝 모델이 예측한 값과 실제 정답의 차이를 손실함수라고 부른다. 우리가 손실함수라고 부르는 이 함수의 최소값을 구할 때는 함수에 대한 미분이 필요하다.
            
    - 03 텐서플로 자료구조
        
        
        앞의 예제에서 파이썬 자료형에 해당하는 정수 1과 2를 텐서플로 연산의 입력값으로 사용했다. 이때 파이썬 자료형 값들은 텐서플로 자료구조인 텐서(Tensor)로 변환되어 처리된다. 텐서플로에서 자료를 표현하는 기본 구조인 텐서에 대해 알아보기로 한다.
        
        <텐서의 종류>
        
        Scalar               Vector         Matrix      Tensor / rank-3, rank-4, rank-5
        
        0차원 텐서인 스칼라(Scalar), 1차원 벡터(Vector), 2차원 행렬(Martix), 3차원 텐서와 4차원 텐서까지 차수가 1씩 증가함에 따라 데이터 구조가 확장된다. 점이 선으로 변하고, 선이 면으로 다시 면이 입체로 변하는 공간 개념을 떠올리도록 하자.
        
        여기서 차수(차원의 수)는 텐서를 구성하는 벡터의 개수를 나타낸다. 벡터는 어떤 축 방향으로 어떤 양이 존재하는 것을 표현한다. 따라서 각 차원은 각각 고유의 정보를 나타내는 축이라고 이해할 수 있다. 2차원 행렬의 경우 1차원 벡터들을 더룬 츅 방향으로 나열하는 개념이다.
        
        <aside>
        🚓 [Tip] 텐서의 어원을 찾아보면 ‘어떤 방향으로 뻗다’, ‘잡아당기다’라는 뜻을 갖는 라틴어인 ‘tensus’에서 유래했다고 한다. 좌표계에서 벡터는 크기와 방향을 갖는다. 즉 방향성을 갖는 어떤 물리량이면서, 텐서 개념을 이해하는 기초가 된다.
        
        </aside>
        
        - 3-1 스칼라(Scalar)
            
            
            스칼라는 정수나 실수와 같은 상수(Constant Number)를 나타낸다고 이해하면 쉽다.
            
            양을 나타내기는 하지만, 방향성을 갖지는 않는다. 따라서 벡터가 존재하지 않기 때문에 차수가 0이 된다. 텐서플로에서는 ‘랭크(rank)-0’ 텐서라고 부른다. 여기서 랭크는 앞에서 설명한 텐서의 차수를 나타낸다. 스칼라는 벡터가 없는 0차원으로 표현되기 때문에 ‘랭크-0’ 텐서라고 정의한다.
            
            <Scalar>
            
                                      shape = () → rank: 0
            
            Scalar →             [ 10 ] 
            
            스칼라 텐서는 constant 함수에 상수 값을 입력해서 만들 수 있다. 변수 a에는 스칼라 1을 할당하고, 변수 b에는 스칼라 2를 저장하고, 변수 a와 b를 print 함수로 출력해 본다. 정수 1과 2는 텐서(tf.Tensor)로 변환된 것을 알 수 있다. 여기서 배열의 크기를 나타내는 shape=()값을 보면, 배열을 나타내는 값이 존재하지 않기 때문에 0차원이라고 보면 된다. 즉, 정수 1과 2는 0차원 텐서인 스칼라로 저장된 것을 확인할 수 있다.
            
            ```python
            [1] # 텐서플로 불러오기
            import tensorflow as tf
            
            #스칼라 정의하기
            a = tf.constant(1)
            b = tf.constant(2)
            
            print("a:", a)
            print("b,", a)
            
            # a: tf.Tensor(1, shape=(), dtype=int32)
            # b: tf.Tensor(2, shape=(), dtype=int32)
            ```
            
            <aside>
            🚓 여기서 dtype은 텐서에 저장된 값의 자료형을 나타낸다. int32는 32비트 정수형이라는 뜻이다.
            
            </aside>
            
            rank 함수를 사용하면 텐서 객체의 랭크(차수)를 알 수 있다. 변수 a에 저장된 텐서의 랭크를 출력하면 값이 0이다. 따라서 랭크가 0인 스칼라 텐서라는 것을 확인할 수 있다.
            
            ```python
            [2] # 랭크 확인하기
            print(tf.rank(a))
            
            # tf.Tensor(0, shape=(), dtype=int32)
            ```
            
            텐서 자료형을 변환하고 싶을 때 cast 함수를 사용하면 된다. 32비트 정수형을 나타내는 int32로 저장되어 있는데, 32비트 실수형을 나타내는 float32로 변환해 본다.
            
            ```python
            [3] # 자료형 변환
            a = tf.cast( a, tf.float32)
            b = tf.cast( b, tf.float32)
            print(a.dtype)
            print(b.dtype)
            
            # <dtype: 'float32'>
            # <dtype: 'float32'>
            ```
            
            <aside>
            🚓 [Tip] 텐서플로 딥러닝 연산에서는 float32를 숫자형 데이터를 나타내는 기본 자료형으로 사용한다.
            
            </aside>
            
            math 모듈에는 여러 가지 수학 함수가 정의되어 있다. 텐서 간의 덧셈은 add 함수를 사용한다. 스칼라 텐서와 a와 스칼라 텐서 b를 더한 결과를 변수 c에 대입하고 출력해 보면, 실수형 값인 3.0이 저장되어 있다. 스칼라 텐서를 서로 더한 결과도 스칼라 텐서이므로 랭크는 0이 된다.
            
            ```python
            [4] # 덧셈 
            c = tf.math.add( a, b)
            print("result:", c)
            print("rank:", tf.rank( c ) )
            
            # result: tf.Tensor(3.0, shape=(), dtype=float32)
            # rank: tf.Tensor(0, shape=(), dtype=int32)
            ```
            
            스칼라 사이에 뺄셈, 곱셈, 나눗셈과 같은 다른 사칙연산을 적용할 수도 있다. 각각 순서대로  subtract, multiply, divide 함수를 사용한다.
            
            ```python
            [5] # 뺄셈
            print(tf.math.subtract(a, b))
            
            # tf.Tensor(-1.0, shape=(), dtype=float32)
            ```
            
            ```python
            [6] # 곱셈
            print(tf.math.multiply(a, b))
            
            # tf.Tensor(2.0, shape=(), dtype=float32)
            ```
            
            ```python
            [7] # 나눗셈
            print(tf.math.divide(a, b))
            
            # tf.Tensor(0.5, shape=(), dtype=float32)
            ```
            
            나눗셈의 나머지를 구할 때는 mod 함수를 사용한다. 파이썬의 % 연산자를 사용한 결과와 같다.
            
            ```python
            [8] # 나눗셈 (나머지)
            print(tf.math.mod(a, b))
            
            # tf.Tensor(1.0, shape=(), dtype=float32)
            ```
            
            나눗셈의 몫을 구할 때는 floordiv 함수를 사용한다. 파이썬의 // 연산자를 사용한 결과와 같다.
            
            ```python
            [9] # 나눗셈(몫)
            print(tf.math.floordiv(a, b))
            
            # tf.Tensor(0.0, shape=(), dtype=float32)
            ```
            
            <aside>
            🚓 [Tip] 이외에도 math 모듈은 여러 가지 수학 함수를 지원하고 있다. 텐서플로 공식 문서에서 확인할 수 있다.
            
            </aside>
            
        - 3-2 벡터(Vector)
            
            
            벡터에는 여러 개의 스칼라 값을 원소로 갖는 1차원 배열로 표현된다. 스칼라 여러 개가 동일한 축방향으로 나열되는 개념이다. 벡터는 원소로 구성되는 여러 개의 값들이 모여서 하나의 대표성을 갖는 값이 된다. 좌표계 공간으로 표현하면 어떤 방향으로 크기를 갖는다. 따라서 각 원소값의 크기뿐만 아니라, 원소들이 나열되는 순서도 의미가 있다.
            
            그림에서 원소가 되는 10, 20, 30은 각각 스칼라이고 이들이 모여서 1차원 텐서인 벡터가 된다. 형태만 보면 파이썬 리스트와 비슷하다. 벡터는 하나의 축을 갖기 때문에 차수가 1이고, ‘랭크-1’ 텐서라고 부른다.
            
                                                          
            
                                                                          / → rank: 1
            
                                                            shape=(3, )
            
                                                      /       /       /   
            
            Vector               →            [10,   20,   30]
            
            [10][20][30]                      - - - - - - - - → axis 0
            
             예제를 통해 텐서플로에서 벡터를 정의하는 방법을 알아본다. constant 함수에 1차원 배열을 입력하면 1차원 텐서인 벡터로 변환된다. 이때, 함수의 입력값으로 파이썬 리스트와 넘파이 배열을 모두 사용할 수 있다. 벡터의 shape 속성은 ( 원소 개수,  ) 형태로 표시된다.
            
            ```python
            [1] # 라이브러리 불러오기
            import tensorflow as tf
            import numpy as np
            
            # 1차원 배열 정의
            py_list = [10, 20, 30] #파이썬 리스트 활용
            num_arr = np.array( [10., 10., 10.] ) #넘파이 배열 활용
            
            # 텐서 변환
            vec1 = tf.constant( py_list, dtype=tf.float32 )
            vec2 = tf.constant( num_arr, dtype=tf.float32 )
            
            # 텐서 출력
            print("vec1:", vec1)
            print("vec2:", vec2)
            
            # vec1: tf.Tensor([10. 20. 30.], shape=(3,), dtype=float32)
            # vec2: tf.Tensor([10. 10. 10.], shape=(3,), dtype=float32)
            ```
            
            실행 결과에서 텐서의 shape 속성은 (3, )과 같이 1개의 축에 대해서만 크기가 표현된다. 1개의 축에 3개의 원소가 있다는 뜻이다. 즉. 1개의 축을 갖는 것을 알 수 있다. dtype 속성을 보면 텐서로 변환된 뒤에도 원본 배열의 실수형 속성이 그대로 유지되고 있다.
            
            shape 속성에서 차수를 알 수 있지만, 텐서플로 rank 함수를 사용하면 텐서의 차수를 반환해 준다. 다음 예제에서 2개의 벡터 모두 랭크가 1인 랭크-1 텐서라는 것을 알 수 있다.
            
            ```python
            [2] # 랭크 확인
            print(tf.rank( vec1 ) )
            print(tf.rank( vec2 ) )
            
            # tf.Tensor(1, shape=(), dtype=int32)
            # tf.Tensor(1, shape=(), dtype=int32)
            ```
            
            tf.math 모듈의 add 함수로 덧셈 연산을 처리한다. 이때 같은 위치에 있는 원소들끼리(element-by-element)짝을 이루어 계산한다. 원소 3개를 갖는 벡터(랭크-1 텐서) 형태가 그대로 유지된다.
            
            ```python
            [3] # 덧셈 함수
            add1 = tf.math.add(vec1, vec2)
            print("result:", add1)
            print("rank:", tf.rank(add1))
            
            # result: tf.Tensor([20. 30. 40.], shape=(3,), dtype=float32)
            # rank: tf.Tensor(1, shape=(), dtype=int32)
            ```
            
                     —  vec1 —→  [ 10, 20, 30 ], rank:1  shape=(3, )
            
                  /
            
            add - [
            
        
                           \
        
                               —  vec1 —→  [ 10, 10, 10 ], rank:1  shape=(3, )
        
                  |
        
             —→    result —→ [20, 30, 40], rank:1 shape=(3, )
        
        파이썬에 내장된 덧셈 연산자 + 를 사용할 수도 있다. 앞에서 add 연산자를 사용한 경우와 결과가 같다.
        
        ```python
        [4] # 덧셈 연산자
        add2 = vec1 + vec2
        print("result:", add2)
        print("rank:", tf.rank(add2))
        
        # result: tf.Tensor([20. 30. 40.], shape=(3,), dtype=float32)
        # rank: tf.Tensor(1, shape=(), dtype=int32)
        ```
        
        스칼라와 마찬가지로 벡터에 대해서도 tf.math 모듈의 여러 가지 함수를 사용하여 산술연산을 처리할 수 있다. 이때, 같은 위치에 있는 원소들끼리 연산을 하는 점에 유의한다.
        
        ```python
        [5] # tf.math 모듈 함수
        print(tf.math.subtract( vec1, vec2 ))
        print(tf.math.multiply( vec1, vec2 ))
        print(tf.math.divide( vec1, vec2 ))
        print(tf.math.mod( vec1, vec2 ))
        print(tf.math.floordiv( vec1, vec2))
        
        # tf.Tensor([ 0. 10. 20.], shape=(3,), dtype=float32)
        # tf.Tensor([100. 200. 300.], shape=(3,), dtype=float32)
        # tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)
        # tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)
        # tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)
        ```
        
        파이썬 연산자를 사용해도 동일한 결과를 얻을 수 있다. 같은 위치의 원소들끼리 계산된다.
        
        ```python
        [6] # 파이썬 연산자
        print( vec1 - vec2 )
        print( vec2 * vec2 )
        print( vec1 / vec2 )
        print( vec1 % vec2 )
        print( vec1 // vec2 )
        
        # tf.Tensor([ 0. 10. 20.], shape=(3,), dtype=float32)
        # tf.Tensor([100. 100. 100.], shape=(3,), dtype=float32)
        # tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)
        # tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)
        # tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)
        ```
        
        벡터를 구성하는 원소들의 합계도 구할 수 있다. reduce_sum 함수를 이용한다. 합계는 스칼라로 표현되는 것을 알 수 있다.
        
        ```python
        [7] # 합계 구하기
        print(tf.reduce_sum( vec1 ))
        print(tf.reduce_sum( vec2 ))
        
        # tf.Tensor(60.0, shape=(), dtype=float32)
        # tf.Tensor(30.0, shape=(), dtype=float32)
        ```
        
        math 모듈의 square 함수를 이용하면 거듭제곱 연산을 처리할 수 있다. 각 원소를 거듭제곱한 결과를 벡터로 변환해 준다.